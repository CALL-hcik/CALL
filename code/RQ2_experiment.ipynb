{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ2: Real Survey Analysis Experiment\n",
    "\n",
    "This notebook analyzes the 20th Presidential Election voter consciousness survey data.\n",
    "Supports both jinbo (liberal) and bosu (conservative) perspectives with 23 political opinion questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.special import rel_entr\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"YOUR_GOOGLE_API_KEY_HERE\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"YOUR_OPENAI_API_KEY_HERE\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"YOUR_ANTHROPIC_API_KEY_HERE\")\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "PERSPECTIVE = \"jinbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(prompt, model_type=\"gemini\", **kwargs):\n",
    "    if model_type == \"gemini\":\n",
    "        model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    elif model_type == \"gpt\":\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            **kwargs\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    elif model_type == \"claude\":\n",
    "        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "        message = client.messages.create(\n",
    "            model=\"claude-3-5-haiku-20241022\",\n",
    "            max_tokens=kwargs.get(\"max_tokens\", 4096),\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return message.content[0].text\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PERSPECTIVE == \"jinbo\":\n",
    "    fm_sample = pd.read_csv(\"../dataset/community_samples/pp_sample_50000.csv\", encoding=\"utf-8-sig\")\n",
    "    index_path = \"../dataset/faiss/pp_embeddings_faiss_50000.index\"\n",
    "else:\n",
    "    fm = pd.read_csv(\"../dataset/community_samples/fm_sample_50000.csv\")\n",
    "    mlb = pd.read_csv(\"../dataset/community_samples/mlb_sample_50000.csv\")\n",
    "    fm_sample = pd.concat([fm, mlb])\n",
    "    index_path = \"../dataset/faiss/bosu_embeddings_faiss_50000.index\"\n",
    "\n",
    "embedding_model = SentenceTransformer(\"intfloat/multilingual-e5-small\", device=\"cuda\")\n",
    "\n",
    "if os.path.exists(index_path):\n",
    "    index = faiss.read_index(index_path)\n",
    "    print(f\"Loaded FAISS index: {index.ntotal} vectors\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"FAISS index not found: {index_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_chunk_length=512):\n",
    "    words = text.split()\n",
    "    chunks, current = [], []\n",
    "    for word in words:\n",
    "        if len(\" \".join(current + [word])) <= max_chunk_length:\n",
    "            current.append(word)\n",
    "        else:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current = [word]\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "    return chunks\n",
    "\n",
    "text_chunks_unique = []\n",
    "seen_chunks = set()\n",
    "\n",
    "for _, row in fm_sample.iterrows():\n",
    "    for chunk in chunk_text(str(row[\"Text\"])):\n",
    "        if chunk not in seen_chunks:\n",
    "            seen_chunks.add(chunk)\n",
    "            chunked_row = row.to_dict()\n",
    "            chunked_row[\"Text\"] = chunk\n",
    "            text_chunks_unique.append(chunked_row)\n",
    "\n",
    "chunked_df = pd.DataFrame(text_chunks_unique)\n",
    "chunked_df[\"ProcessedText\"] = chunked_df[\"Text\"].apply(lambda x: f\"query: {x}\")\n",
    "print(f\"Chunked DataFrame: {len(chunked_df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey Questions (23 Questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refer to ksdc data (https://www.ksdcdb.kr/data/dataSearchResView.do?surveyId=2825)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_QUESTIONS = {\n",
    "    \"33\": [\n",
    "        \"나 같은 사람에게는 투표만이 정부에 대해 말할 수 있는 유일한 방법이다\",\n",
    "        \"나 같은 사람이 정부가 하는 일에 대해 뭐라고 평가할 수 없다\",\n",
    "        \"나 같은 사람에게는 정치나 정부가 하는 일이 너무 복잡해서 이해할 수가 없다\",\n",
    "        \"투표는 아주 많은 사람들이 하기 때문에 내가 투표하는가 안하는가는 그리 중요하지 않다\",\n",
    "        \"만약 내가 지지하는 후보(또는 정당)가 선거에서 이길 확률이 없다면, 내가 투표하는 것은 별로 의미가 없다\",\n",
    "        \"어떤 후보에게 표를 던지느냐가 미래의 일에 중요한 영향을 미친다\"\n",
    "    ],\n",
    "    \"34_1\": [\"한미동맹관계를 더욱 강화해야 한다\"],\n",
    "    \"34_2\": [\"상황에 관계 없이 대북지원은 지속되어야 한다\"],\n",
    "    \"34_3\": [\"소수자에 대한 지원과 보호는 더욱 강화되어야 한다\"],\n",
    "    \"34_4\": [\"난민과 이민자에 대한 문호를 더 개방해야 한다\"],\n",
    "    \"34_5\": [\"복지보다는 경제발전에 더욱 힘을 기울여야 한다\"],\n",
    "    \"34_6\": [\"기업과 고소득자들이 현재보다 세금을 더 많이 내게 해야 한다\"],\n",
    "    \"34_7\": [\"자유가 평등보다 더 중요하다\"],\n",
    "    \"34_8\": [\"자유가 안보보다 더 중요하다\"],\n",
    "    \"36\": [\n",
    "        '대부분의 정치인은 국민에게 관심이 없다',\n",
    "        '대부분의 정치인은 신뢰할 수 없다',\n",
    "        '정치인들이 우리나라의 가장 큰 문제이다',\n",
    "        '정치인은 문제해결을 위해 때로는 규칙을 어길수도 있다',\n",
    "        '가장 중요한 정책결정은 국민보다 정치인한테 맡겨야 한다',\n",
    "        '대부분의 정치인은 부자와 권력자의 이익을 지킬 뿐이다',\n",
    "    ],\n",
    "    \"37\": [\n",
    "        \"나라가 어려운 상황에 처했을 때 정부는 법을 어기더라도 일을 해내는 것이 중요하다\",\n",
    "        \"국회와 언론이 정부를 지나치게 감시하면 정부는 일을 할 수 없다\",\n",
    "        \"우리나라의 발전을 위해서 독재시절의 방식도 사용해야 한다\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "QUESTION_LABELS = {\n",
    "    \"33\": \"투표\", \"34_1\": \"동맹\", \"34_2\": \"대북지원\", \"34_3\": \"소수자\",\n",
    "    \"34_4\": \"난민\", \"34_5\": \"경제발전\", \"34_6\": \"세금\", \"34_7\": \"평등\",\n",
    "    \"34_8\": \"안보\", \"36\": \"정치인\", \"37\": \"독재\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever and Summarizer Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT_PROMPT = \"\"\"\n",
    "Please write exactly two lines in Korean about the topic '{topic}':\n",
    "1. The first line should briefly state the reason for supporting.\n",
    "2. The second line should briefly state the reason for opposing.\n",
    "\"\"\"\n",
    "\n",
    "SUMMARIZER_PROMPT = \"\"\"\n",
    "You are a sophisticated qualitative analysis AI.\n",
    "Your primary function is to extract and analyze multiple dominant themes from social media posts.\n",
    "Your goal is to identify the various topics, sentiments, and arguments that emerge in public discussions.\n",
    "\n",
    "Core Task: Extract Multiple Dominant Themes\n",
    "Answer the question: \"{question}\" based on the provided posts.\n",
    "Rather than finding a single 'center', identify ALL significant themes that appear in the conversation.\n",
    "\n",
    "Analysis Workflow:\n",
    "1. Initial Scanning: Read all posts to identify distinct themes and topics being discussed.\n",
    "2. Theme Extraction: Identify 2-4 major themes based on frequency, engagement, and significance.\n",
    "3. Sentiment Analysis per Theme: For each identified theme, analyze the associated sentiments and arguments.\n",
    "\n",
    "Theme Identification Guidelines:\n",
    "- Each theme should be distinct and substantive enough to stand alone\n",
    "- Themes can be completely unrelated to each other\n",
    "- Include both majority and significant minority themes\n",
    "- For each theme, accurately represent its dominant sentiment without artificial balancing\n",
    "\n",
    "Posts:\n",
    "{opinions}\n",
    "\n",
    "Output Format (Korean):\n",
    "<answer>\n",
    "1. [Theme]: [Key points and sentiment summary]\n",
    "2. [Theme]: [Key points and sentiment summary]\n",
    "3. [Theme]: [Key points and sentiment summary]\n",
    "</answer>\n",
    "\"\"\"\n",
    "\n",
    "AGENT_PROMPT = \"\"\"\n",
    "Based on the analysis below, select your answer from the options.\n",
    "{analysis}\n",
    "\n",
    "Question: {question}\n",
    "Options: {options}\n",
    "\n",
    "Return only your choice (e.g., \"1. Strongly Disagree\").\n",
    "\"\"\"\n",
    "\n",
    "def run_retriever(question, top_k=50, model_type=\"gemini\"):\n",
    "    aug_prompt = AUGMENT_PROMPT.format(topic=question)\n",
    "    aug_response = call_llm(aug_prompt, model_type=model_type)\n",
    "    \n",
    "    query_emb = embedding_model.encode([f\"query: {aug_response}\"], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    distances, indices = index.search(query_emb, top_k)\n",
    "    return chunked_df.iloc[indices[0]][\"Text\"].tolist()\n",
    "\n",
    "def run_summarizer(question, texts, model_type=\"gemini\"):\n",
    "    opinions = \"\\n---\\n\".join(texts)\n",
    "    prompt = SUMMARIZER_PROMPT.format(question=question, opinions=opinions)\n",
    "    return call_llm(prompt, model_type=model_type)\n",
    "\n",
    "def run_agent(analysis, question, options, model_type=\"gemini\"):\n",
    "    prompt = AGENT_PROMPT.format(analysis=analysis, question=question, options=options)\n",
    "    return call_llm(prompt, model_type=model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPTIONS_5 = \"['1. Strongly Disagree', '2. Generally Disagree', '3. So-so', '4. Generally Agree', '5. Strongly Agree']\"\n",
    "OPTIONS_4 = \"['1. Strongly Disagree', '2. Generally Disagree', '3. Generally Agree', '4. Strongly Agree']\"\n",
    "\n",
    "top_k = 50\n",
    "num_iterations = 100\n",
    "save_path = f\"../results/RQ2/{PERSPECTIVE}\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "for model_type in [\"gemini\", \"gpt\", \"claude\"]:\n",
    "    print(f\"\\n=== Running with {model_type} ===\")\n",
    "    \n",
    "    for option_key, questions in SURVEY_QUESTIONS.items():\n",
    "        options = OPTIONS_5 if option_key == \"36\" else OPTIONS_4\n",
    "        results = []\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        for question in tqdm(questions, desc=f\"{option_key}\"):\n",
    "            for seed in range(num_iterations):\n",
    "                retrieved = run_retriever(question, top_k, model_type)\n",
    "                summary = run_summarizer(question, retrieved, model_type)\n",
    "                response = run_agent(summary, question, options, model_type)\n",
    "                \n",
    "                results.append({\n",
    "                    \"question\": question,\n",
    "                    \"seed\": seed,\n",
    "                    \"answer_response\": response,\n",
    "                    \"method\": \"ours\"\n",
    "                })\n",
    "                time.sleep(2)\n",
    "        \n",
    "        pd.DataFrame(results).to_csv(\n",
    "            f\"{save_path}/{PERSPECTIVE}_ours_{model_type}_{option_key}_{timestamp}.csv\",\n",
    "            index=False, encoding=\"utf-8-sig\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Real Survey Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president_20th = pd.read_csv(\"../dataset/RQ2_ksdc/20th_president.csv\", encoding=\"cp949\")\n",
    "president_20th = president_20th.dropna()\n",
    "\n",
    "if PERSPECTIVE == \"bosu\":\n",
    "    survey_data = president_20th[president_20th[\"q5\"].isin([1, 2])]\n",
    "else:\n",
    "    survey_data = president_20th[president_20th[\"q5\"].isin([4, 5])]\n",
    "\n",
    "print(f\"Survey respondents ({PERSPECTIVE}): {len(survey_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis (KL Divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distribution(series, num_categories=5):\n",
    "    counts = series.value_counts()\n",
    "    dist = np.zeros(num_categories)\n",
    "    for cat, count in counts.items():\n",
    "        if 1 <= cat <= num_categories:\n",
    "            dist[int(cat)-1] = count\n",
    "    return dist / dist.sum() if dist.sum() > 0 else dist\n",
    "\n",
    "def kl_divergence(P, Q, epsilon=1e-10):\n",
    "    P = np.asarray(P, dtype=np.float64) + epsilon\n",
    "    Q = np.asarray(Q, dtype=np.float64) + epsilon\n",
    "    P = P / np.sum(P)\n",
    "    Q = Q / np.sum(Q)\n",
    "    return np.sum(rel_entr(P, Q))\n",
    "\n",
    "def compare_distributions(ground_truth_df, predictions_dict, questions, num_categories=5):\n",
    "    results = []\n",
    "    for question in questions:\n",
    "        gt_dist = calculate_distribution(ground_truth_df[question], num_categories)\n",
    "        row = {\"question\": question}\n",
    "        for method_name, pred_df in predictions_dict.items():\n",
    "            pred_dist = calculate_distribution(pred_df[question], num_categories)\n",
    "            row[method_name] = kl_divergence(gt_dist, pred_dist)\n",
    "        results.append(row)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Results and Calculate KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOICE_MAP = {\n",
    "    \"Strongly Disagree\": 1, \"1. Strongly Disagree\": 1, \"1\": 1,\n",
    "    \"Generally Disagree\": 2, \"2. Generally Disagree\": 2, \"2\": 2,\n",
    "    \"So-so\": 3, \"3. So-so\": 3, \"3\": 3,\n",
    "    \"Generally Agree\": 3, \"3. Generally Agree\": 3,\n",
    "    \"Strongly Agree\": 4, \"4. Strongly Agree\": 4, \"4\": 4,\n",
    "    \"5. Strongly Agree\": 5, \"5\": 5\n",
    "}\n",
    "\n",
    "def parse_response(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    x_str = str(x).strip()\n",
    "    for key, val in CHOICE_MAP.items():\n",
    "        if key in x_str:\n",
    "            return val\n",
    "    match = re.search(r\"(\\d)\", x_str)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "result_files = glob.glob(f\"{save_path}/{PERSPECTIVE}_ours_*.csv\")\n",
    "if result_files:\n",
    "    all_results = pd.concat([pd.read_csv(f, encoding=\"utf-8-sig\") for f in result_files])\n",
    "    all_results[\"parsed_response\"] = all_results[\"answer_response\"].apply(parse_response)\n",
    "    print(f\"Total responses: {len(all_results)}\")\n",
    "    print(f\"Valid responses: {all_results['parsed_response'].notna().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
